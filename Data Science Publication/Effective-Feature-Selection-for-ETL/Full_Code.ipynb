{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X before making numerical: \n",
      " [[111 'M' '1/1/2018' '22/1/1990' 900 'M' 555 28 '8/1/2018' 909 776 112233\n",
      "  'akkas' 123 111 'ctg' 7765 1122]\n",
      " [112 'B' '2/1/2018' '20/9/1989' 901 'F' 501 29 '9/1/2018' 991 667 990077\n",
      "  'nusrat' 321 123 'dhaka' 4788 1456]\n",
      " [113 'M' '3/1/2018' '1/11/1993' 902 'M' 502 19 '10/1/2018' 992 555 123456\n",
      "  'kalam' 132 124 'Korimpur' 6754 5532]\n",
      " [114 'M' '3/1/2018' '2/11/1990' 903 'M' 503 23 '10/1/2018' 993 777 880965\n",
      "  'robiul' 120 246 'birampur' 7754 5322]\n",
      " [115 'M' '4/1/2018' '22/9/1988' 904 'M' 504 24 '11/1/2018' 994 445 235765\n",
      "  'jamal' 123 467 'syria' 6754 6543]\n",
      " [116 'B' '4/1/2018' '31/12/1982' 905 'F' 505 26 '11/1/2018' 995 336 345865\n",
      "  'kamal' 564 756 'agrabad' 8534 6433]\n",
      " [117 'B' '22/2/2018' '15/9/1993' 906 'M' 506 40 '28/2/2018' 996 365 349065\n",
      "  'nizam' 546 456 'gec' 7643 7898]\n",
      " [118 'B' '25/2/2018' '26/5/1997' 907 'M' 507 41 '28/2/2018' 997 334 357852\n",
      "  'amin' 789 797 'halisohor' 7543 7946]\n",
      " [119 'M' '3/3/2018' '11/2/1978' 908 'M' 508 43 '13/3/2018' 998 975 120956\n",
      "  'onik' 987 567 'dinajpur' 7643 4567]\n",
      " [120 'M' '5/3/2018' '16/12/1971' 909 'F' 509 46 '13/3/2018' 999 365 437865\n",
      "  'minhaz' 897 466 'rongpur' 7426 5476]\n",
      " [121 'M' '7/3/2018' '26/3/1972' 910 'M' 510 9 '23/3/2018' 1001 309 192830\n",
      "  'raju' 879 467 'kamalpur' 3678 45768]\n",
      " [122 'B' '10/3/2018' '23/4/1995' 911 'M' 511 10 '23/3/2018' 1101 936\n",
      "  706123 'akash' 907 432 'amlapur' 3468 4578]\n",
      " [123 'M' '16/3/2018' '14/5/1996' 912 'M' 512 12 '29/3/2018' 1189 854\n",
      "  490123 'batas' 107 678 'jamlapur' 8653 353]\n",
      " [124 'B' '19/3/2018' '19/9/1980' 913 'F' 513 14 '30/3/2018' 1230 468\n",
      "  358524 'hotas' 309 665 'hamlapur' 8643 2356]]\n",
      "\n",
      "X after making numerical: \n",
      " [[111 'M' 0 8 900 1 555 8 7 909 776 112233 1 123 111 4 7765 1122]\n",
      " [112 'B' 4 7 901 0 501 9 8 991 667 990077 10 321 123 5 4788 1456]\n",
      " [113 'M' 7 0 902 1 502 4 0 992 555 123456 6 132 124 0 6754 5532]\n",
      " [114 'M' 7 6 903 1 503 5 0 993 777 880965 13 120 246 3 7754 5322]\n",
      " [115 'M' 9 9 904 1 504 6 1 994 445 235765 5 123 467 13 6754 6543]\n",
      " [116 'B' 9 13 905 0 505 7 1 995 336 345865 7 564 756 1 8534 6433]\n",
      " [117 'B' 5 3 906 1 506 10 4 996 365 349065 9 546 456 7 7643 7898]\n",
      " [118 'B' 6 12 907 1 507 11 4 997 334 357852 2 789 797 8 7543 7946]\n",
      " [119 'M' 8 1 908 1 508 12 2 998 975 120956 11 987 567 6 7643 4567]\n",
      " [120 'M' 10 4 909 0 509 13 2 999 365 437865 8 897 466 12 7426 5476]\n",
      " [121 'M' 11 11 910 1 510 0 3 1001 309 192830 12 879 467 11 3678 45768]\n",
      " [122 'B' 1 10 911 1 511 1 3 1101 936 706123 0 907 432 2 3468 4578]\n",
      " [123 'M' 2 2 912 1 512 2 5 1189 854 490123 3 107 678 10 8653 353]\n",
      " [124 'B' 3 5 913 0 513 3 6 1230 468 358524 4 309 665 9 8643 2356]] \n",
      "\n",
      "Index(['id', 'diagnosis', 'Invoice Date', 'Date of birth', 'Invoice No',\n",
      "       'Gender', 'Test Name', 'Age', 'Delivery Date', 'Department', 'Sample',\n",
      "       'Contact number', 'patient name', 'Unit', 'Reference Value', 'Address',\n",
      "       'Test Attribute', 'Result'],\n",
      "      dtype='object')\n",
      "Score list: [  6.75000000e-01   7.14285714e-01   2.70750000e+00   9.65217160e+01\n",
      "   2.28528451e+05   2.75625000e+00   1.36290323e-01   1.70545910e+04]\n",
      "Feature list: Index(['Date of birth', 'Gender', 'Age', 'Sample', 'Contact number',\n",
      "       'patient name', 'Address', 'Result'],\n",
      "      dtype='object')\n",
      "Chosen best 5 feature by rfe: Index(['Gender', 'Sample', 'Contact number', 'patient name', 'Result'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 8\n",
      "Best features : Index(['Date of birth', 'Gender', 'Age', 'Sample', 'Contact number',\n",
      "       'patient name', 'Address', 'Result'],\n",
      "      dtype='object')\n",
      "Effective Feature:  {'patient name', 'Gender', 'Result', 'Sample', 'Contact number'}\n",
      "1 :Contact number\n",
      "2 :Result\n",
      "3 :Sample\n",
      "4 :patient name\n",
      "5 :Gender\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#importing the dataset\n",
    "data = pd.read_csv('Update (1).csv')\n",
    "\n",
    "#Before making anything like feature selection,feature extraction and classification, firstly we start with basic data analysis. Lets look at features of data.\n",
    "data.head()  # head method show only first 5 rows\n",
    "\n",
    "#. Pandas has a helpful select_dtypes function which we can use to build a new dataframe containing only the object columns.\n",
    "obj_data = data.select_dtypes(include=['object']).copy()\n",
    "obj_data.head()\n",
    "\n",
    "#Input   [Encoding Categorical Values]\n",
    "X = data.iloc[:,0:18].values \n",
    "print(\"\\nX before making numerical: \\n\",X)\n",
    "\n",
    "\n",
    "#taking careof categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,2]= labelencoder_X.fit_transform(X[:,2])\n",
    "X[:,3]= labelencoder_X.fit_transform(X[:,3])\n",
    "X[:,5]= labelencoder_X.fit_transform(X[:,5])\n",
    "X[:,7]= labelencoder_X.fit_transform(X[:,7])\n",
    "X[:,8]= labelencoder_X.fit_transform(X[:,8])\n",
    "X[:,12]= labelencoder_X.fit_transform(X[:,12])\n",
    "X[:,15]= labelencoder_X.fit_transform(X[:,15])\n",
    "print(\"\\nX after making numerical: \\n\",X,\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(X, columns = ['id', 'diagnosis', 'Invoice Date', 'Date of birth', 'Invoice No', 'Gender', 'Test Name', 'Age',\t'Delivery Date', 'Department', 'Sample', 'Contact number', 'patient name', 'Unit', 'Reference Value', 'Address', 'Test Attribute', 'Result'])\n",
    "\n",
    "\n",
    "# 1) There is an id that cannot be used for classificaiton 2) Diagnosis is our class label)\n",
    "#Therefore, drop these unnecessary features.\n",
    "# feature names as a list\n",
    "col = df.columns       # .columns gives columns names in data \n",
    "print(col)\n",
    "\n",
    "# y includes our labels and x includes our features\n",
    "y = df.diagnosis\n",
    "list = ['id','diagnosis']\n",
    "x = df.drop(list,axis = 1 )\n",
    "x.head()\n",
    "\n",
    "\n",
    "#1) Feature selection with correlation and random forest classification\n",
    "\n",
    "drop_list1 = ['Invoice No','Invoice Date','Test Name','Delivery Date','Department','Unit','Reference Value','Test Attribute']\n",
    "x_1 = x.drop(drop_list1,axis = 1 )        # do not modify x, we will use it later \n",
    "p = []\n",
    "p.append(x_1.columns.tolist())\n",
    "x_1.head()\n",
    "\n",
    "\n",
    "\n",
    "data_dia = y\n",
    "data = x\n",
    "data_n_2 = (data - data.mean()) / (data.std())              # standardization\n",
    "data = pd.concat([y,data_n_2.iloc[:,0:18]],axis=1)\n",
    "data = pd.melt(data,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "\n",
    "\n",
    "# split data train 70 % and test 30 %\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#random forest classifier with n_estimators\n",
    "clf_rf = RandomForestClassifier(random_state=43)      \n",
    "clr_rf = clf_rf.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#2) Univariate feature selection and random forest classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# find best scored features\n",
    "select_feature = SelectKBest(chi2, k=5).fit(x_train, y_train)\n",
    "\n",
    "print('Score list:', select_feature.scores_)\n",
    "print('Feature list:', x_train.columns)\n",
    "p.append(x_train.columns.values.tolist())\n",
    "\n",
    "scores = {}\n",
    "for u, v in zip(select_feature.scores_, x_train.columns.values.tolist()):\n",
    "    scores[v] = u\n",
    "scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3) Recursive feature elimination (RFE) with random forest\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "# Create the RFE object and rank each pixel\n",
    "clf_rf_1 = RandomForestClassifier()      \n",
    "rfe = RFE(estimator=clf_rf_1, n_features_to_select=5, step=1)\n",
    "rfe = rfe.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Chosen best 5 feature by rfe:',x_train.columns[rfe.support_])\n",
    "\n",
    "\n",
    "p.append(x_train.columns[rfe.support_].values.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#4) Recursive feature elimination with cross validation and random forest classification\n",
    "\n",
    "#Now we will not only find best features but we also find how many features do we need.\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "clf_rf_2 = RandomForestClassifier() \n",
    "rfecv = RFECV(estimator=clf_rf_2, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(x_train, y_train)\n",
    "\n",
    "print('Optimal number of features :', rfecv.n_features_)\n",
    "print('Best features :', x_train.columns[rfecv.support_])\n",
    "\n",
    "p.append(x_train.columns[rfecv.support_].values.tolist())\n",
    "\n",
    "\n",
    "p\n",
    "\n",
    "\n",
    "\n",
    "result = set(p[0])\n",
    "for s in p[1:]:\n",
    "    result.intersection_update(s)\n",
    "print(\"Effective Feature: \",result)\n",
    "\n",
    "output = []\n",
    "for s in result:\n",
    "    output.append((s, scores[s]))\n",
    "output = sorted(output, reverse=True, key=lambda tup: tup[1])\n",
    "output\n",
    "\n",
    "for i, v in enumerate(output):\n",
    "    print(str(i + 1) + ' :' + v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
